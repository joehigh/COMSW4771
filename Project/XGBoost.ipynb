{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import skimage.io as skim\n",
    "import skimage.transform as skt\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import cv2\n",
    "import math\n",
    "from sklearn.datasets import load_sample_image\n",
    "import sklearn.metrics as skm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = pd.read_csv('train.csv')\n",
    "test_meta = pd.read_csv('test.csv')\n",
    "\n",
    "train_path = train_target['filename']\n",
    "test_path = test_meta['filename']\n",
    "\n",
    "labels = list(set(train_target['label'].to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = [os.path.join('data/train', file) for file in os.listdir('data/train')]\n",
    "train_imgs_sort = sorted(train_images)  \n",
    "train_array = np.array(train_imgs_sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel1 = [224,224,3]\n",
    "pixel2 = [229,229,3]\n",
    "pixel3 = [255,255,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data, pixel):\n",
    "    x_new=np.zeros((len(data),pixel[0],pixel[1],pixel[2]))\n",
    "    for i,d in enumerate(data):\n",
    "        x_new[i,:,:,:] = d\n",
    "    return x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "for f in train_path.to_list():\n",
    "    xray = skim.imread(f)\n",
    "    xray = skt.resize(xray, pixel1)\n",
    "    x.append(xray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(set(train_target['label'].to_list()))\n",
    "n_cat = len(labels)\n",
    "labeler = {i:labels[i] for i in range(n_cat)}\n",
    "rev_labeler = {labeler[i]:i for i in labeler.keys()}\n",
    "\n",
    "y = [rev_labeler[i] for i in train_target['label'].to_list()]\n",
    "y_targ = train_target['label']\n",
    "y_targ = np.array(y_targ)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=4321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocess(X_train, pixel1)\n",
    "X_train_pp = []\n",
    "\n",
    "for elem in X_train:\n",
    "    elem = np.ndarray.flatten(elem)\n",
    "    X_train_pp.append(elem)\n",
    "X_train_pp = np.array(X_train_pp)\n",
    "\n",
    "X_test = preprocess(X_test, pixel1)\n",
    "X_test_pp = []\n",
    "for elem in X_test:\n",
    "    elem = np.ndarray.flatten(elem)\n",
    "    X_test_pp.append(elem)\n",
    "X_test_pp = np.array(X_test_pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler_fit = scaler.fit(X_train_pp)\n",
    "X_train2 = scaler_fit.transform(X_train_pp)\n",
    "X_test2 = scaler_fit.transform(X_test_pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dmatrix = xgb.DMatrix(X_train2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\"objective\":\"multi:softmax\",'max_depth':6, 'num_class':4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = xgb.cv(params, x_dmatrix, nfold=4, num_boost_round=20, metrics=\"merror\", as_pandas=True)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param_dist = {\"objective\":\"multi:softmax\", \"max_depth\":4, \"n_estimators\":250, \"learning_rate\":0.01, \"num_class\":4, \n",
    "#              \"subsample\":0.4, \"reg_lambda\":2, \"reg_alpha\":1, \"min_child_weight\":1,\"gamma\":0.3, \"colsample_bytree\":1.0, \"num_boost_round\":20}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train an XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = xgb.XGBClassifier(objective='multi:softmax', n_estimators=1000, as_pandas=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb_clf.fit(X_train2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_model.predict(X_test2)\n",
    "accuracy = float(np.sum(y_pred==y_test))/len(y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = skm.accuracy_score(y_test, y_pred)\n",
    "bal_accuracy = skm.balanced_accuracy_score(y_test, y_pred)\n",
    "print(\"accuracy: %f\" % (acc))\n",
    "print(\"balanced accuracy: %f\" % (bal_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = []\n",
    "for im in test_path.to_list():\n",
    "    i = skim.imread(im)\n",
    "    i = skt.resize(i,[224,224,3])\n",
    "    x_test.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = preprocess(x_test, pixel1)\n",
    "x_test_pp = []\n",
    "for elem in x_test:\n",
    "    elem = np.ndarray.flatten(elem)\n",
    "    x_test_pp.append(elem)\n",
    "x_test_pp = np.array(x_test_pp)\n",
    "x2 = scaler_fit.transform(x_test_pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = xgb_model.predict(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {'Id':range(len(test_pred)),'label':[labeler[i] for i in test_pred]}\n",
    "submission = pd.DataFrame.from_dict(output)\n",
    "\n",
    "submission.to_csv('jph2185_submission8.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning/Optimization using Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_cl = xgb.XGBClassifier(objective=\"multi:softmax\")\n",
    "\n",
    "param_dist = {\n",
    "    'gamma': [0.3,  0.5,  1, 1.5, 2],\n",
    "    'n_estimators': [100, 250, 500],\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'max_depth': [2,4,7,10],\n",
    "    'subsample': [0.2, 0.4, 0.5, 0.6, 0.7],\n",
    "    'colsample_bytree': [0.3, 0.6, 0.8, 1.0],\n",
    "    'min_child_weight': [1, 3, 5, 7],\n",
    "    'reg_alpha': [0, 0.5, 1],\n",
    "    'reg_lambda': [0, 1, 1.5, 2, 3, 4.5],  \n",
    "}\n",
    "\n",
    "xgb_rscv = RandomizedSearchCV(xg_cl, param_distributions=param_dist, scoring=\"balanced_accuracy\", cv=5, n_iter=5, verbose=3, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgboost = xgb_rscv.fit(X_train2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model best estimators\n",
    "print(\"Learning Rate: \", model_xgboost.best_estimator_.get_params()[\"learning_rate\"])\n",
    "print(\"Gamma: \", model_xgboost.best_estimator_.get_params()[\"gamma\"])\n",
    "print(\"Max Depth: \", model_xgboost.best_estimator_.get_params()[\"max_depth\"])\n",
    "print(\"Subsample: \", model_xgboost.best_estimator_.get_params()[\"subsample\"])\n",
    "print(\"Max Features at Split: \", model_xgboost.best_estimator_.get_params()[\"colsample_bytree\"])\n",
    "print(\"Alpha: \", model_xgboost.best_estimator_.get_params()[\"reg_alpha\"])\n",
    "print(\"Lamda: \", model_xgboost.best_estimator_.get_params()[\"reg_lambda\"])\n",
    "print(\"Minimum Sum of the Instance Weight Hessian to Make a Child: \",\n",
    "      model_xgboost.best_estimator_.get_params()[\"min_child_weight\"])\n",
    "print(\"Number of Trees: \", model_xgboost.best_estimator_.get_params()[\"n_estimators\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
