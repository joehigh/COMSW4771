{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import *\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn as sk\n",
    "import skimage.io as skim\n",
    "import skimage.transform as skt\n",
    "from sklearn.datasets import load_sample_image\n",
    "import sklearn.metrics as skm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import joblib\n",
    "\n",
    "import tensorflow as tf\n",
    "from PIL import Image, ImageOps\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import csv\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = pd.read_csv('train.csv')\n",
    "test_meta = pd.read_csv('test.csv')\n",
    "\n",
    "train_path = train_target['filename']\n",
    "test_path = test_meta['filename']\n",
    "\n",
    "labels = list(set(train_target['label'].to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = [os.path.join('data/train', file) for file in os.listdir('data/train')]\n",
    "train_imgs_sort = sorted(train_images)  \n",
    "train_array = np.array(train_imgs_sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel1 = [224,224,3]\n",
    "pixel2 = [229,229,3]\n",
    "pixel3 = [255,255,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data, pixel):\n",
    "    x_new=np.zeros((len(data),pixel[0],pixel[1],pixel[2]))\n",
    "    for i,d in enumerate(data):\n",
    "        x_new[i,:,:,:] = d\n",
    "    return x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "for f in train_path.to_list():\n",
    "    xray = skim.imread(f)\n",
    "    xray = skt.resize(xray, pixel1)\n",
    "    x.append(xray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'covid', 1: 'bacterial', 2: 'viral', 3: 'normal'}\n",
      "{'covid': 0, 'bacterial': 1, 'viral': 2, 'normal': 3}\n",
      "[3, 2, 2, 1, 2]\n",
      "['normal' 'viral' 'viral' ... 'bacterial' 'covid' 'bacterial']\n"
     ]
    }
   ],
   "source": [
    "labels = list(set(train_target['label'].to_list()))\n",
    "n_cat = len(labels)\n",
    "labeler = {i:labels[i] for i in range(n_cat)}\n",
    "rev_labeler = {labeler[i]:i for i in labeler.keys()}\n",
    "\n",
    "y = [rev_labeler[i] for i in train_target['label'].to_list()]\n",
    "y_targ = train_target['label']\n",
    "y_targ = np.array(y_targ)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_labels = np.zeros((len(y_targ), num_classes))  #one-hot encode target labels\n",
    "# one-hot encoding the labels\n",
    "for ii in range(len(y_targ)):\n",
    "    jj = np.where(labels == y_targ[ii])\n",
    "    ohe_labels[ii, jj] = 1\n",
    "ohe_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_holdout, y_train, y_holdout = train_test_split(x, ohe_labels, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocess(X_train, pixel1)\n",
    "X_train_pp = []\n",
    "\n",
    "for elem in X_train:\n",
    "    #elem = np.ndarray.flatten(elem)\n",
    "    X_train_pp.append(elem)\n",
    "#X_train_pp = np.array(X_train_pp)\n",
    "\n",
    "X_test = preprocess(X_test, pixel1)\n",
    "X_test_pp = []\n",
    "for elem in X_test:\n",
    "    #elem = np.ndarray.flatten(elem)\n",
    "    X_test_pp.append(elem)\n",
    "#X_test_pp = np.array(X_test_pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras VGG16 Pre-trained model using SGD optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model = keras.applications.vgg16.VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "for layer in vgg16_model.layers:\n",
    "    model.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.Dense at 0x7fe27c929c18>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(SGD(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pp = np.array(X_train_pp)\n",
    "X_holdout_pp = np.array(X_holdout_pp)\n",
    "y_train = np.array(y_train)\n",
    "y_holdout = np.array(y_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_train = ImageDataGenerator(rotation_range=15, width_shift_range=0.5, shear_range=0.3, height_shift_range=0.5, zoom_range=0.15)\n",
    "gen_test = ImageDataGenerator()\n",
    "\n",
    "train_generator = gen_train.flow(X_train_pp, y_train)\n",
    "test_generator = gen_test.flow(X_holdout_pp, y_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      " - 22s - loss: 1.3873 - acc: 0.0859 - val_loss: 1.3879 - val_acc: 0.0625\n",
      "Epoch 2/25\n",
      " - 18s - loss: 1.3872 - acc: 0.0625 - val_loss: 1.3866 - val_acc: 0.1231\n",
      "Epoch 3/25\n",
      " - 20s - loss: 1.3871 - acc: 0.0625 - val_loss: 1.3877 - val_acc: 0.0563\n",
      "Epoch 4/25\n",
      " - 18s - loss: 1.3873 - acc: 0.0475 - val_loss: 1.3876 - val_acc: 0.0923\n",
      "Epoch 5/25\n",
      " - 18s - loss: 1.3869 - acc: 0.0898 - val_loss: 1.3871 - val_acc: 0.1154\n",
      "Epoch 6/25\n",
      " - 20s - loss: 1.3872 - acc: 0.0625 - val_loss: 1.3874 - val_acc: 0.2062\n",
      "Epoch 7/25\n",
      " - 18s - loss: 1.3871 - acc: 0.0703 - val_loss: 1.3876 - val_acc: 0.2308\n",
      "Epoch 8/25\n",
      " - 17s - loss: 1.3869 - acc: 0.1069 - val_loss: 1.3871 - val_acc: 0.3000\n",
      "Epoch 9/25\n",
      " - 19s - loss: 1.3868 - acc: 0.1836 - val_loss: 1.3874 - val_acc: 0.2500\n",
      "Epoch 10/25\n",
      " - 18s - loss: 1.3870 - acc: 0.2266 - val_loss: 1.3871 - val_acc: 0.3385\n",
      "Epoch 11/25\n",
      " - 18s - loss: 1.3870 - acc: 0.2602 - val_loss: 1.3870 - val_acc: 0.3000\n",
      "Epoch 12/25\n",
      " - 18s - loss: 1.3868 - acc: 0.3008 - val_loss: 1.3871 - val_acc: 0.3154\n",
      "Epoch 13/25\n",
      " - 18s - loss: 1.3869 - acc: 0.3164 - val_loss: 1.3870 - val_acc: 0.3154\n",
      "Epoch 14/25\n",
      " - 19s - loss: 1.3869 - acc: 0.3008 - val_loss: 1.3872 - val_acc: 0.2750\n",
      "Epoch 15/25\n",
      " - 17s - loss: 1.3867 - acc: 0.3254 - val_loss: 1.3873 - val_acc: 0.2846\n",
      "Epoch 16/25\n",
      " - 18s - loss: 1.3867 - acc: 0.3164 - val_loss: 1.3867 - val_acc: 0.3154\n",
      "Epoch 17/25\n",
      " - 19s - loss: 1.3865 - acc: 0.3516 - val_loss: 1.3867 - val_acc: 0.3125\n",
      "Epoch 18/25\n",
      " - 18s - loss: 1.3867 - acc: 0.2852 - val_loss: 1.3871 - val_acc: 0.2846\n",
      "Epoch 19/25\n",
      " - 18s - loss: 1.3867 - acc: 0.3343 - val_loss: 1.3869 - val_acc: 0.3063\n",
      "Epoch 20/25\n",
      " - 18s - loss: 1.3866 - acc: 0.3086 - val_loss: 1.3867 - val_acc: 0.3154\n",
      "Epoch 21/25\n",
      " - 18s - loss: 1.3864 - acc: 0.3398 - val_loss: 1.3870 - val_acc: 0.2769\n",
      "Epoch 22/25\n",
      " - 19s - loss: 1.3864 - acc: 0.3076 - val_loss: 1.3868 - val_acc: 0.3125\n",
      "Epoch 23/25\n",
      " - 18s - loss: 1.3866 - acc: 0.3125 - val_loss: 1.3865 - val_acc: 0.3154\n",
      "Epoch 24/25\n",
      " - 18s - loss: 1.3866 - acc: 0.2656 - val_loss: 1.3869 - val_acc: 0.2769\n",
      "Epoch 25/25\n",
      " - 19s - loss: 1.3863 - acc: 0.3281 - val_loss: 1.3865 - val_acc: 0.3063\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe27e6d1b00>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, steps_per_epoch=8, validation_data=test_generator, validation_steps=5, epochs=25, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras VGG16 Pre-trained model using Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.Dense at 0x7fe27ace95f8>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_train = ImageDataGenerator(rotation_range=10, width_shift_range=0.5, shear_range=0.2, height_shift_range=0.5, zoom_range=0.1)\n",
    "gen_test = ImageDataGenerator()\n",
    "\n",
    "train_generator = train_gen.flow(X_train_new, y_train)\n",
    "test_generator = test_gen.flow(X_holdout_new, y_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      " - 15s - loss: 1.4033 - acc: 0.2500 - val_loss: 1.3757 - val_acc: 0.2969\n",
      "Epoch 2/25\n",
      " - 11s - loss: 1.3599 - acc: 0.3438 - val_loss: 1.3645 - val_acc: 0.2959\n",
      "Epoch 3/25\n",
      " - 12s - loss: 1.4145 - acc: 0.2500 - val_loss: 1.3714 - val_acc: 0.3047\n",
      "Epoch 4/25\n",
      " - 10s - loss: 1.3919 - acc: 0.3203 - val_loss: 1.3692 - val_acc: 0.2857\n",
      "Epoch 5/25\n",
      " - 11s - loss: 1.3367 - acc: 0.3438 - val_loss: 1.3710 - val_acc: 0.3281\n",
      "Epoch 6/25\n",
      " - 11s - loss: 1.3498 - acc: 0.3203 - val_loss: 1.3689 - val_acc: 0.2551\n",
      "Epoch 7/25\n",
      " - 11s - loss: 1.3693 - acc: 0.3594 - val_loss: 1.3939 - val_acc: 0.2734\n",
      "Epoch 8/25\n",
      " - 10s - loss: 1.2880 - acc: 0.4305 - val_loss: 1.3382 - val_acc: 0.3265\n",
      "Epoch 9/25\n",
      " - 11s - loss: 1.4121 - acc: 0.2656 - val_loss: 1.3703 - val_acc: 0.3047\n",
      "Epoch 10/25\n",
      " - 11s - loss: 1.3378 - acc: 0.3594 - val_loss: 1.3682 - val_acc: 0.2857\n",
      "Epoch 11/25\n",
      " - 12s - loss: 1.3654 - acc: 0.3438 - val_loss: 1.3716 - val_acc: 0.3203\n",
      "Epoch 12/25\n",
      " - 11s - loss: 1.3336 - acc: 0.3438 - val_loss: 1.3658 - val_acc: 0.2653\n",
      "Epoch 13/25\n",
      " - 12s - loss: 1.4038 - acc: 0.2266 - val_loss: 1.3486 - val_acc: 0.3047\n",
      "Epoch 14/25\n",
      " - 10s - loss: 1.4285 - acc: 0.2656 - val_loss: 1.3947 - val_acc: 0.2857\n",
      "Epoch 15/25\n",
      " - 11s - loss: 1.3335 - acc: 0.3720 - val_loss: 1.3951 - val_acc: 0.3125\n",
      "Epoch 16/25\n",
      " - 10s - loss: 1.3319 - acc: 0.3516 - val_loss: 1.3333 - val_acc: 0.2755\n",
      "Epoch 17/25\n",
      " - 11s - loss: 1.4040 - acc: 0.2734 - val_loss: 1.3586 - val_acc: 0.2812\n",
      "Epoch 18/25\n",
      " - 10s - loss: 1.4234 - acc: 0.1953 - val_loss: 1.3802 - val_acc: 0.3163\n",
      "Epoch 19/25\n",
      " - 11s - loss: 1.3605 - acc: 0.3359 - val_loss: 1.3740 - val_acc: 0.2734\n",
      "Epoch 20/25\n",
      " - 10s - loss: 1.3906 - acc: 0.3203 - val_loss: 1.3591 - val_acc: 0.3265\n",
      "Epoch 21/25\n",
      " - 12s - loss: 1.3336 - acc: 0.4141 - val_loss: 1.3833 - val_acc: 0.2812\n",
      "Epoch 22/25\n",
      " - 10s - loss: 1.3949 - acc: 0.2395 - val_loss: 1.3460 - val_acc: 0.3163\n",
      "Epoch 23/25\n",
      " - 11s - loss: 1.4270 - acc: 0.3047 - val_loss: 1.3564 - val_acc: 0.2891\n",
      "Epoch 24/25\n",
      " - 11s - loss: 1.3186 - acc: 0.3281 - val_loss: 1.3802 - val_acc: 0.3061\n",
      "Epoch 25/25\n",
      " - 11s - loss: 1.3172 - acc: 0.3359 - val_loss: 1.3983 - val_acc: 0.2344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe27a4c7ef0>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, steps_per_epoch=4, validation_data=test_generator, validation_steps=4, epochs=25, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
